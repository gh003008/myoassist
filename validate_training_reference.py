#!/usr/bin/env python3
"""
í•™ìŠµ ì‹œì‘ ì „ Reference Motion ê²€ì¦ ë„êµ¬

í•™ìŠµì— ì‚¬ìš©ë  ì •í™•í•œ reference motionì„ ì‹œê°í™”í•˜ì—¬ ê²€ì¦í•©ë‹ˆë‹¤.
í™˜ê²½ í•¸ë“¤ëŸ¬ê°€ ë¡œë“œí•œ ë°ì´í„°ë¥¼ ê·¸ëŒ€ë¡œ ê°€ì ¸ì™€ ë Œë”ë§í•©ë‹ˆë‹¤.
"""
import numpy as np
import mujoco
import imageio
from pathlib import Path
from datetime import datetime
import argparse


def visualize_training_reference(config_path, output_dir='training_reference_validation'):
    """
    í•™ìŠµì—ì„œ ì‹¤ì œë¡œ ì‚¬ìš©ë  reference motionì„ ì‹œê°í™”
    
    Args:
        config_path: í•™ìŠµ config JSON íŒŒì¼ ê²½ë¡œ
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
    """
    from rl_train.envs.environment_handler import EnvironmentHandler
    import rl_train.train.train_configs.config as myoassist_config
    
    print(f"\n{'='*100}")
    print(f"í•™ìŠµ Reference Motion ê²€ì¦ ë„êµ¬")
    print(f"{'='*100}\n")
    
    # 1. Config ë¡œë“œ (í•™ìŠµê³¼ ë™ì¼í•œ ë°©ì‹)
    print(f"ğŸ“‹ Step 1: Config ë¡œë“œ")
    print(f"   íŒŒì¼: {config_path}\n")
    
    default_config = EnvironmentHandler.get_session_config_from_path(
        config_path, 
        myoassist_config.TrainSessionConfigBase
    )
    config_type = EnvironmentHandler.get_config_type_from_session_id(
        default_config.env_params.env_id
    )
    config = EnvironmentHandler.get_session_config_from_path(config_path, config_type)
    
    # 2. Reference Data ë¡œë“œ (í•™ìŠµê³¼ ë™ì¼í•œ ë°©ì‹)
    print(f"\nğŸ“Š Step 2: Reference Data ë¡œë“œ (í™˜ê²½ í•¸ë“¤ëŸ¬ ì‚¬ìš©)")
    ref_data = EnvironmentHandler.load_reference_data(config)
    
    if ref_data is None:
        print("âŒ Reference dataê°€ ì—†ìŠµë‹ˆë‹¤!")
        return
    
    # ê²€ì¦ ì •ë³´ ì¶œë ¥
    series_data = ref_data['series_data']
    metadata = ref_data['metadata']
    
    print(f"\nâœ… ë¡œë“œ ì™„ë£Œ!")
    print(f"   ë°ì´í„° ê¸¸ì´: {metadata['resampled_data_length']} frames")
    print(f"   ìƒ˜í”Œë§ ë ˆì´íŠ¸: {metadata['resampled_sample_rate']} Hz")
    print(f"   DOF: {metadata.get('dof', 'N/A')}")
    
    # ë°ì´í„° í‚¤ í™•ì¸
    position_keys = [k for k in series_data.keys() if not k.startswith('d')]
    print(f"   Position í‚¤: {sorted(position_keys)[:5]}... (showing first 5)")
    print(f"   ì´ {len(position_keys)}ê°œ DOF")
    
    # 3. q_ref í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (ë Œë”ë§ìš©)
    print(f"\nğŸ”„ Step 3: ë Œë”ë§ í˜•ì‹ìœ¼ë¡œ ë³€í™˜")
    
    # Reference joint ìˆœì„œ ì •ì˜ (environmentì—ì„œ ì‚¬ìš©í•˜ëŠ” ìˆœì„œ)
    # Environment formatì€ q_ prefixê°€ ìˆì„ ìˆ˜ ìˆìŒ
    ref_joints_no_prefix = [
        'pelvis_tx', 'pelvis_ty', 'pelvis_tz',
        'pelvis_tilt', 'pelvis_list', 'pelvis_rotation',
        'hip_flexion_r', 'hip_adduction_r', 'hip_rotation_r',
        'hip_flexion_l', 'hip_adduction_l', 'hip_rotation_l',
        'knee_angle_r', 'knee_angle_l',
        'ankle_angle_r', 'ankle_angle_l'
    ]
    
    # Check if data has q_ prefix
    first_key = list(series_data.keys())[0]
    has_q_prefix = first_key.startswith('q_') and not first_key.startswith('dq_')
    
    if has_q_prefix:
        ref_joints = ['q_' + joint for joint in ref_joints_no_prefix]
        print(f"   ë°ì´í„° í˜•ì‹: q_ prefix ìˆìŒ")
    else:
        ref_joints = ref_joints_no_prefix
        print(f"   ë°ì´í„° í˜•ì‹: q_ prefix ì—†ìŒ")
    
    # q_ref ë°°ì—´ ìƒì„±
    q_ref = np.column_stack([series_data[joint] for joint in ref_joints])
    print(f"   q_ref shape: {q_ref.shape}")
    
    # ëŒ€ì¹­ì„± ê²€ì¦
    print(f"\nğŸ” Step 4: ëŒ€ì¹­ì„± ê²€ì¦")
    symmetric_pairs = [
        ('hip_flexion_l', 'hip_flexion_r', 9, 6),
        ('hip_adduction_l', 'hip_adduction_r', 10, 7),
        ('hip_rotation_l', 'hip_rotation_r', 11, 8),
        ('knee_angle_l', 'knee_angle_r', 13, 12),
        ('ankle_angle_l', 'ankle_angle_r', 15, 14),
    ]
    
    print(f"{'Joint Pair':<40} {'Range Diff':<12} {'Status'}")
    print(f"{'-'*70}")
    
    for left_name, right_name, left_idx, right_idx in symmetric_pairs:
        left_vals = q_ref[:, left_idx]
        right_vals = q_ref[:, right_idx]
        
        left_range = left_vals.max() - left_vals.min()
        right_range = right_vals.max() - right_vals.min()
        range_diff = abs(left_range - right_range)
        
        is_symmetric = range_diff < 0.05
        status = "âœ… Symmetric" if is_symmetric else "âš ï¸  Asymmetric"
        
        print(f"{left_name} vs {right_name:<20} {range_diff:>8.4f} rad   {status}")
    
    # 5. ëª¨ë¸ ë¡œë“œ ë° ë Œë”ë§
    print(f"\nğŸ¬ Step 5: ë Œë”ë§ ì‹œì‘")
    model = mujoco.MjModel.from_xml_path(config.env_params.model_path)
    data_mj = mujoco.MjData(model)
    
    # Joint name to qpos index mapping
    joint_to_qpos = {}
    for i in range(model.njnt):
        jnt_name = model.joint(i).name
        qpos_addr = model.jnt_qposadr[i]
        joint_to_qpos[jnt_name] = qpos_addr
    
    # ë§¤í•‘ ìƒì„±
    ref_to_qpos = []
    # Use joints without q_ prefix for matching with MuJoCo model
    for ref_idx, jnt_name_with_prefix in enumerate(ref_joints):
        # Remove q_ prefix for MuJoCo joint name matching
        if jnt_name_with_prefix.startswith('q_'):
            jnt_name = jnt_name_with_prefix[2:]
        else:
            jnt_name = jnt_name_with_prefix
            
        if jnt_name in joint_to_qpos:
            qpos_idx = joint_to_qpos[jnt_name]
            ref_to_qpos.append((ref_idx, qpos_idx, jnt_name))
    
    print(f"   Joint ë§¤í•‘: {len(ref_to_qpos)}ê°œ")
    
    # ë Œë”ëŸ¬ ì„¤ì •
    renderer = mujoco.Renderer(model, height=720, width=1920)
    
    # ì¹´ë©”ë¼ ì„¤ì • (multiview)
    camera_front = mujoco.MjvCamera()
    mujoco.mjv_defaultFreeCamera(model, camera_front)
    camera_front.azimuth = 90
    camera_front.elevation = -15
    camera_front.distance = 4.5
    camera_front.lookat[:] = [0, 0.7, 0]
    
    camera_side = mujoco.MjvCamera()
    mujoco.mjv_defaultFreeCamera(model, camera_side)
    camera_side.azimuth = 180
    camera_side.elevation = -20
    camera_side.distance = 3.0
    camera_side.lookat[:] = [0, 0.4, 0]
    
    # ë Œë”ë§ ì˜µì…˜
    scene_option = mujoco.MjvOption()
    scene_option.flags[mujoco.mjtVisFlag.mjVIS_TRANSPARENT] = True
    scene_option.flags[mujoco.mjtVisFlag.mjVIS_CONTACTPOINT] = False
    
    # Floor íˆ¬ëª…í•˜ê²Œ
    for i in range(model.ngeom):
        geom_name = mujoco.mj_id2name(model, mujoco.mjtObj.mjOBJ_GEOM, i)
        if geom_name and 'floor' in geom_name.lower():
            model.geom_rgba[i, 3] = 0.3
    
    # Arms ìˆ¨ê¹€
    for i in range(model.ngeom):
        geom_name = mujoco.mj_id2name(model, mujoco.mjtObj.mjOBJ_GEOM, i)
        if geom_name and any(part in geom_name.lower() for part in ['humer', 'ulna', 'radius', 'hand', 'arm']):
            model.geom_rgba[i, 3] = 0.0
    
    # ë Œë”ë§
    print(f"   ë Œë”ë§ ì¤‘...")
    frames = []
    num_frames = 900  # Increased from 600 for smoother, longer video
    frame_skip = max(1, q_ref.shape[0] // num_frames)
    
    for i in range(0, min(num_frames * frame_skip, q_ref.shape[0]), frame_skip):
        # Stand keyframeìœ¼ë¡œ ì´ˆê¸°í™”
        key_id = mujoco.mj_name2id(model, mujoco.mjtObj.mjOBJ_KEY, "stand")
        data_mj.qpos[:] = model.key_qpos[key_id]
        
        # Reference motion ì ìš©
        for ref_idx, qpos_idx, jnt_name in ref_to_qpos:
            data_mj.qpos[qpos_idx] = q_ref[i, ref_idx]
        
        # Pelvis height ì¡°ì • (ì´ë¯¸ í™˜ê²½ í•¸ë“¤ëŸ¬ì—ì„œ +0.91m ì ìš©ë¨)
        # ì¶”ê°€ ì¡°ì • ì—†ì´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        
        # Arms ì¤‘ë¦½ ìì„¸
        arm_joints = {
            40: 0.0, 41: 0.0, 42: 0.5, 43: 0.8,  # Right
            47: 0.0, 48: 0.0, 49: 0.5, 50: 0.8,  # Left
        }
        for qpos_idx, angle in arm_joints.items():
            if qpos_idx < len(data_mj.qpos):
                data_mj.qpos[qpos_idx] = angle
        
        # Forward kinematics
        mujoco.mj_forward(model, data_mj)
        
        # Multiview ë Œë”ë§
        renderer.update_scene(data_mj, camera=camera_front, scene_option=scene_option)
        pixels_front = renderer.render()
        front_half = pixels_front[:, 480:1440]
        
        renderer.update_scene(data_mj, camera=camera_side, scene_option=scene_option)
        pixels_side = renderer.render()
        side_half = pixels_side[:, 480:1440]
        
        pixels = np.concatenate([front_half, side_half], axis=1)
        frames.append(pixels)
        
        if (i // frame_skip) % 50 == 0:
            print(f"   Frame {i // frame_skip}/{num_frames}...", end='\r')
    
    print(f"\n   ë Œë”ë§ ì™„ë£Œ!")
    
    # 6. ë¹„ë””ì˜¤ ì €ì¥
    print(f"\nğŸ’¾ Step 6: ë¹„ë””ì˜¤ ì €ì¥")
    
    output_path = Path(output_dir)
    output_path.mkdir(exist_ok=True)
    
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    video_file = output_path / f"{timestamp}_training_reference_validation.mp4"
    
    fps = 30
    imageio.mimsave(str(video_file), frames, fps=fps)
    
    print(f"   ì €ì¥ ì™„ë£Œ: {video_file}")
    print(f"   FPS: {fps}")
    print(f"   Duration: {len(frames)/fps:.1f}ì´ˆ")
    
    # 7. ìš”ì•½ ë¦¬í¬íŠ¸
    print(f"\n{'='*100}")
    print(f"âœ… ê²€ì¦ ì™„ë£Œ!")
    print(f"{'='*100}")
    print(f"\nğŸ“Š Reference Motion ìš”ì•½:")
    print(f"   íŒŒì¼: {config.env_params.reference_data_path}")
    print(f"   í”„ë ˆì„: {metadata['resampled_data_length']}")
    print(f"   ìƒ˜í”Œë§: {metadata['resampled_sample_rate']} Hz")
    print(f"   DOF: {metadata.get('dof', len(ref_joints))}")
    print(f"   Duration: {metadata['resampled_data_length'] / metadata['resampled_sample_rate']:.1f}ì´ˆ")
    
    print(f"\nğŸ¥ ì¶œë ¥:")
    print(f"   ë¹„ë””ì˜¤: {video_file}")
    
    print(f"\nâš ï¸  ì¤‘ìš”:")
    print(f"   ì´ ë¹„ë””ì˜¤ê°€ í•™ìŠµì—ì„œ ì‹¤ì œë¡œ ì‚¬ìš©ë˜ëŠ” reference motionì…ë‹ˆë‹¤!")
    print(f"   í•™ìŠµ ì „ ë°˜ë“œì‹œ í™•ì¸í•˜ì„¸ìš”:")
    print(f"   - Kinematic chainì´ ì •ìƒì¸ê°€? (ì •ê°•ì´ê°€ í™ì— ì•ˆ ë¶™ì—ˆë‚˜?)")
    print(f"   - ëŒ€ì¹­ì„±ì´ ì˜¬ë°”ë¥¸ê°€? (ì¢Œìš° ë‹¤ë¦¬ê°€ ëŒ€ì¹­ì¸ê°€?)")
    print(f"   - Pelvis ë†’ì´ê°€ ì ì ˆí•œê°€? (ë•…ì— ë„ˆë¬´ ê°€ê¹ì§€ ì•Šë‚˜?)")
    print(f"{'='*100}\n")
    
    return video_file


def main():
    parser = argparse.ArgumentParser(
        description='í•™ìŠµ ì‹œì‘ ì „ Reference Motion ê²€ì¦'
    )
    parser.add_argument('--config', type=str,
                       default='rl_train/train/train_configs/S004_3D_IL_ver2_1_BALANCE.json',
                       help='í•™ìŠµ config JSON íŒŒì¼')
    parser.add_argument('--output', type=str,
                       default='training_reference_validation',
                       help='ì¶œë ¥ ë””ë ‰í† ë¦¬')
    
    args = parser.parse_args()
    
    visualize_training_reference(args.config, args.output)


if __name__ == '__main__':
    main()

# S004 Motion Imitation Learning Pipeline

ì´ ê°€ì´ë“œëŠ” OpenSim ëª¨ì…˜ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ MyoAssistì—ì„œ ëª¨ë°©í•™ìŠµ(Imitation Learning)ì„ ì‹¤í–‰í•˜ëŠ” ì „ì²´ ì›Œí¬í”Œë¡œìš°ë¥¼ ì„¤ëª…í•©ë‹ˆë‹¤.

## ğŸ“‹ ëª©ì°¨

1. [ëª¨ë°©í•™ìŠµì´ë€?](#ëª¨ë°©í•™ìŠµì´ë€)
2. [ë°ì´í„° ë³€í™˜](#ë°ì´í„°-ë³€í™˜)
3. [í™˜ê²½ ì„¤ì • ê²€ì¦](#í™˜ê²½-ì„¤ì •-ê²€ì¦)
4. [í•™ìŠµ ì‹¤í–‰](#í•™ìŠµ-ì‹¤í–‰)
5. [ê²°ê³¼ í‰ê°€](#ê²°ê³¼-í‰ê°€)
6. [íŠ¸ëŸ¬ë¸”ìŠˆíŒ…](#íŠ¸ëŸ¬ë¸”ìŠˆíŒ…)

---

## ğŸ¯ ëª¨ë°©í•™ìŠµì´ë€?

### MyoAssistì˜ ëª¨ë°©í•™ìŠµ ë°©ì‹

ì´ í”„ë ˆì„ì›Œí¬ëŠ” **"Reference Motion Tracking with Reward Shaping"** ë°©ì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

- **ë°©ì‹**: PPO (Proximal Policy Optimization) + Imitation Reward
- **ì°¨ì´ì **: GAILì´ë‚˜ AIRLì´ ì•„ë‹˜ (Discriminator ì—†ìŒ)
- **íŠ¹ì§•**:
  - Reference trajectoryë¥¼ ì§ì ‘ ë³´ìƒ í•¨ìˆ˜ì— í¬í•¨
  - ê´€ì ˆ ìœ„ì¹˜/ì†ë„ ì°¨ì´ë¥¼ exponential rewardë¡œ ê³„ì‚°
  - ê³„ì‚°ì´ ê°€ë³ê³  êµ¬í˜„ì´ ë‹¨ìˆœ
  - ë¡œë³´í‹±ìŠ¤ ë¶„ì•¼ì—ì„œ ë„ë¦¬ ì‚¬ìš©ë¨

### ë³´ìƒ í•¨ìˆ˜ êµ¬ì¡°

```python
# ê´€ì ˆ ìœ„ì¹˜ ë³´ìƒ
q_reward = dt * exp(-8 * (qpos_diff)Â²)

# ê´€ì ˆ ì†ë„ ë³´ìƒ  
dq_reward = dt * exp(-8 * (qvel_diff)Â²)

# ì´ ë³´ìƒ = ëª¨ë°© ë³´ìƒ + ì „ì§„ ë³´ìƒ + í˜ë„í‹°
```

---

## ğŸ”„ ë°ì´í„° ë³€í™˜

### 1. OpenSim ë°ì´í„° êµ¬ì¡°

OpenSim NPZ íŒŒì¼ì€ ë‹¤ìŒ êµ¬ì¡°ë¥¼ ê°€ì§‘ë‹ˆë‹¤:

```
- model_states: (N, 63) - ì „ì²´ ìƒíƒœ ë°ì´í„°
- model_states_columns: ì»¬ëŸ¼ ì´ë¦„ (63ê°œ)
  - pelvis_tx, pelvis_ty, pelvis_tz
  - knee_angle_r/l, ankle_angle_r/l
  - hip_r/l_0~5 (6DOF íšŒì „/ì´ë™)
  - ê°ì†ë„, ì ‘ì´‰ë ¥ ë“±
- sampling_rate: ìƒ˜í”Œë§ ë ˆì´íŠ¸ (Hz)
- height_m, weight_kg: ì‹ ì²´ ì •ë³´
```

### 2. MyoAssist í˜•ì‹

MyoAssistëŠ” ë‹¤ìŒ êµ¬ì¡°ë¥¼ ìš”êµ¬í•©ë‹ˆë‹¤:

```python
{
    'metadata': {
        'sample_rate': 100,
        'data_length': 12028,
        'height_m': 1.74,
        'weight_kg': 70.56
    },
    'series_data': {
        'q_pelvis_tx': array[N],
        'q_pelvis_ty': array[N],
        'q_pelvis_tilt': array[N],
        'q_hip_flexion_r': array[N],
        'q_hip_flexion_l': array[N],
        'q_knee_angle_r': array[N],
        'q_knee_angle_l': array[N],
        'q_ankle_angle_r': array[N],
        'q_ankle_angle_l': array[N],
        'dq_*': array[N]  # ì†ë„ ë°ì´í„°
    }
}
```

### 3. ë³€í™˜ ì‹¤í–‰

```bash
# ê¸°ë³¸ ë³€í™˜
python opensim2myoassist_converter.py "C:/workspace_home/opensim data/LD_gdp/S004/level_08mps/trial_01.npz" "rl_train/reference_data/S004_trial01_08mps.npz"

# ìƒ˜í”Œë§ ë ˆì´íŠ¸ ì§€ì •
python opensim2myoassist_converter.py input.npz output.npz --sample_rate 30
```

### 4. ë³€í™˜ ê²°ê³¼ í™•ì¸

```bash
python inspect_data_structures.py
```

---

## âœ… í™˜ê²½ ì„¤ì • ê²€ì¦

í•™ìŠµ ì „ì— í™˜ê²½ì´ ì œëŒ€ë¡œ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸:

```bash
python verify_S004_setup.py
```

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë‹¤ìŒì„ í™•ì¸í•©ë‹ˆë‹¤:
- âœ… Reference data ë¡œë“œ ê°€ëŠ¥
- âœ… í•„ìˆ˜ í‚¤ ì¡´ì¬ ì—¬ë¶€
- âœ… í™˜ê²½ ìƒì„± ê°€ëŠ¥
- âœ… í™˜ê²½ reset/step ì‘ë™

---

## ğŸš€ í•™ìŠµ ì‹¤í–‰

### ë°©ë²• 1: ê°„í¸ ìŠ¤í¬ë¦½íŠ¸ (ê¶Œì¥)

```bash
# 1. ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ (ì„¤ì • í™•ì¸ìš©)
python train_S004_motion.py --quick_test

# 2. ê¸°ë³¸ í•™ìŠµ (16ê°œ ë³‘ë ¬ í™˜ê²½)
python train_S004_motion.py

# 3. í™˜ê²½ ê°œìˆ˜ ì¡°ì • (PC ì‚¬ì–‘ì— ë§ì¶¤)
python train_S004_motion.py --num_envs 8

# 4. GPU ì‚¬ìš©
python train_S004_motion.py --device cuda --num_envs 32

# 5. ë Œë”ë§ í¬í•¨
python train_S004_motion.py --render
```

### ë°©ë²• 2: ì§ì ‘ ì‹¤í–‰

```bash
python rl_train/run_train.py --config_file_path rl_train/train/train_configs/S004_trial01_08mps_config.json
```

### í•™ìŠµ ì¤‘ ëª¨ë‹ˆí„°ë§

í•™ìŠµ ì¤‘ì—ëŠ” ë‹¤ìŒ ì •ë³´ê°€ í‘œì‹œë©ë‹ˆë‹¤:
- Rollout ì§„í–‰ ìƒí™©
- í‰ê·  ë³´ìƒ
- Episode ê¸¸ì´
- í•™ìŠµ í†µê³„

ê²°ê³¼ëŠ” `rl_train/results/train_session_[timestamp]/`ì— ì €ì¥ë©ë‹ˆë‹¤.

---

## ğŸ“Š ê²°ê³¼ í‰ê°€

### 1. í•™ìŠµëœ ì •ì±… í‰ê°€

```bash
python rl_train/run_policy_eval.py rl_train/results/train_session_[timestamp]
```

### 2. ìƒì„±ë˜ëŠ” ê²°ê³¼ë¬¼

- `analyze_results_[timesteps]_[num]/`
  - ë³´í–‰ ë¶„ì„ ê·¸ë˜í”„
  - ê´€ì ˆ ê¶¤ì  ë¹„êµ
  - ê·¼ìœ¡ í™œì„±í™” íŒ¨í„´
  - ì˜ìƒ íŒŒì¼ (MP4)

### 3. ì‹¤ì‹œê°„ ì‹œê°í™”

```bash
python rl_train/run_train.py \
    --config_file_path rl_train/results/train_session_[timestamp]/session_config.json \
    --config.env_params.prev_trained_policy_path rl_train/results/train_session_[timestamp]/trained_models/model_[steps] \
    --flag_realtime_evaluate
```

---

## ğŸ›ï¸ ì„¤ì • ì»¤ìŠ¤í„°ë§ˆì´ì§•

### Config íŒŒì¼ ìˆ˜ì •

`rl_train/train/train_configs/S004_trial01_08mps_config.json`:

```json
{
    "total_timesteps": 3e7,  // ì´ í•™ìŠµ ìŠ¤í…
    "env_params": {
        "num_envs": 16,  // ë³‘ë ¬ í™˜ê²½ ê°œìˆ˜
        "min_target_velocity": 0.8,  // ëª©í‘œ ì†ë„ (m/s)
        "reference_data_path": "rl_train/reference_data/S004_trial01_08mps.npz",
        "reward_keys_and_weights": {
            "qpos_imitation_rewards": {
                "knee_angle_l": 1.0,  // ë¬´ë¦ ë³´ìƒ ê°€ì¤‘ì¹˜
                "hip_flexion_l": 0.2,  // ê³ ê´€ì ˆ ë³´ìƒ ê°€ì¤‘ì¹˜
                ...
            }
        }
    },
    "ppo_params": {
        "learning_rate": 0.0001,
        "n_steps": 1024,  // í™˜ê²½ ê°œìˆ˜ì— ë”°ë¼ ì¡°ì •
        "batch_size": 8192,
        "device": "cpu"  // 'cuda' for GPU
    }
}
```

### ë³´ìƒ ê°€ì¤‘ì¹˜ íŠœë‹

ì¤‘ìš”í•œ ê´€ì ˆì— ë” ë†’ì€ ê°€ì¤‘ì¹˜ ë¶€ì—¬:
- `knee_angle_*`: 1.0 (ë¬´ë¦ì´ ì¤‘ìš”)
- `pelvis_tilt`: 1.0 (ìì„¸ ìœ ì§€)
- `hip_flexion_*`: 0.2 (ë¯¸ì„¸ ì¡°ì •)
- `ankle_angle_*`: 0.2 (ë°œëª© ì›€ì§ì„)

---

## ğŸ”§ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### 1. ë©”ëª¨ë¦¬ ë¶€ì¡±

```bash
# ë³‘ë ¬ í™˜ê²½ ê°œìˆ˜ ì¤„ì´ê¸°
python train_S004_motion.py --num_envs 4

# n_steps ì¡°ì • (batch_size ìœ ì§€)
# num_envs * n_steps â‰ˆ 16384
```

### 2. í•™ìŠµì´ ë¶ˆì•ˆì •í•  ë•Œ

Config íŒŒì¼ì—ì„œ ì¡°ì •:
```json
{
    "ppo_params": {
        "learning_rate": 0.00005,  // í•™ìŠµë¥  ê°ì†Œ
        "clip_range": 0.1,  // í´ë¦¬í•‘ ë²”ìœ„ ê°ì†Œ
        "target_kl": 0.005  // KL divergence ì œí•œ ê°•í™”
    }
}
```

### 3. ë³´ìƒì´ ê°œì„ ë˜ì§€ ì•Šì„ ë•Œ

- Reference motion í’ˆì§ˆ í™•ì¸
- ë³´ìƒ ê°€ì¤‘ì¹˜ ì¬ì¡°ì •
- ëª©í‘œ ì†ë„ê°€ referenceì™€ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸
- `out_of_trajectory_threshold` ì¡°ì •

### 4. í™˜ê²½ ìƒì„± ì‹¤íŒ¨

```bash
# ì˜ì¡´ì„± í™•ì¸
pip install -r requirements.txt

# í™˜ê²½ ê²€ì¦
python verify_S004_setup.py
```

### 5. NumPy ë²„ì „ ë¬¸ì œ

```bash
# NumPy í˜¸í™˜ì„± í™•ì¸
pip install numpy==1.23.5
```

---

## ğŸ“š ì¶”ê°€ ë¦¬ì†ŒìŠ¤

### íŠœí† ë¦¬ì–¼ ë…¸íŠ¸ë¶

- `docs/tutorial/rl_imitation_tutorial.ipynb` - ëª¨ë°©í•™ìŠµ ê¸°ì´ˆ
- `docs/tutorial/rl_analyze_tutorial.ipynb` - ê²°ê³¼ ë¶„ì„

### ê´€ë ¨ ë¬¸ì„œ

- [MyoAssist ê³µì‹ ë¬¸ì„œ](https://myoassist.neumove.org/)
- [Reinforcement Learning](https://myoassist.neumove.org/reinforcement-learning/)
- [Configuration Guide](https://myoassist.neumove.org/reinforcement-learning/02_configuration)

### ì°¸ê³  ë…¼ë¬¸

ì´ ë°©ì‹ì€ ë‹¤ìŒê³¼ ìœ ì‚¬í•©ë‹ˆë‹¤:
- DeepMimic (SIGGRAPH 2018)
- Motion Imitation via Deep RL with Reward Shaping

---

## ğŸ‰ ìš”ì•½

```bash
# 1ë‹¨ê³„: ë°ì´í„° ë³€í™˜
python opensim2myoassist_converter.py "input.npz" "output.npz"

# 2ë‹¨ê³„: í™˜ê²½ ê²€ì¦
python verify_S004_setup.py

# 3ë‹¨ê³„: í•™ìŠµ ì‹¤í–‰
python train_S004_motion.py

# 4ë‹¨ê³„: ê²°ê³¼ í‰ê°€
python rl_train/run_policy_eval.py rl_train/results/train_session_[timestamp]
```

---

**ë¬¸ì œê°€ ë°œìƒí•˜ë©´:**
1. `verify_S004_setup.py` ì‹¤í–‰
2. Config íŒŒì¼ì˜ ê²½ë¡œ í™•ì¸
3. Reference data í˜•ì‹ í™•ì¸
4. GitHub Issues ê²€ìƒ‰: https://github.com/neumovelab/myoassist/issues

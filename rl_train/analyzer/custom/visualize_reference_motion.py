"""
Reference Motion Data ì‹œê°í™” ë„êµ¬
==================================

NPZ íŒŒì¼ì˜ reference motionì„ MuJoCo í™˜ê²½ì—ì„œ ë Œë”ë§í•©ë‹ˆë‹¤.

Usage:
    python visualize_reference_motion.py --data rl_train/reference_data/S004_trial01_08mps_3D.npz --output reference_motion.mp4
"""

import numpy as np
import argparse
import json
from pathlib import Path
from rl_train.envs.environment_handler import EnvironmentHandler
import rl_train.train.train_configs.config as myoassist_config

def visualize_reference_motion(config_path, reference_npz_path, output_path, num_frames=300, fps=30, camera_view='side'):
    """Reference motionì„ MuJoCoì—ì„œ ì¬ìƒí•˜ê³  ë¹„ë””ì˜¤ë¡œ ì €ì¥
    
    Args:
        camera_view: 'front', 'side', 'top', 'diagonal' ì¤‘ ì„ íƒ
    """
    
    # Reference ë°ì´í„° ë¡œë“œ
    print(f"ğŸ“‚ Reference ë°ì´í„° ë¡œë“œ: {reference_npz_path}")
    data = np.load(reference_npz_path, allow_pickle=True)
    metadata = data['metadata'].item()
    series_data = data['series_data'].item()
    
    print(f"\nğŸ“Š ë°ì´í„° ì •ë³´:")
    print(f"  - ì´ í”„ë ˆì„ ìˆ˜: {metadata['data_length']}")
    print(f"  - Sampling rate: {metadata['sample_rate']} Hz")
    print(f"  - Duration: {metadata['data_length'] / metadata['sample_rate']:.2f} ì´ˆ")
    print(f"  - Model type: {metadata['model_type']}")
    print(f"  - DOF: {metadata['dof']}")
    print(f"\n  - Position keys: {[k for k in series_data.keys() if k.startswith('q_')]}")
    print(f"  - Velocity keys: {[k for k in series_data.keys() if k.startswith('dq_')]}")
    
    # Config ë¡œë“œ
    print(f"\nâš™ï¸ Config ë¡œë“œ: {config_path}")
    default_config = EnvironmentHandler.get_session_config_from_path(
        config_path, 
        myoassist_config.TrainSessionConfigBase
    )
    config_type = EnvironmentHandler.get_config_type_from_session_id(
        default_config.env_params.env_id
    )
    config = EnvironmentHandler.get_session_config_from_path(config_path, config_type)
    
    # âš ï¸ CRITICAL: Override reference data path with user-specified file
    config.env_params.reference_data_path = reference_npz_path
    print(f"  âœ… Reference data path overridden: {reference_npz_path}")
    
    # ë Œë”ë§ í™˜ê²½ ìƒì„±
    print("ğŸ¥ ë Œë”ë§ í™˜ê²½ ìƒì„± ì¤‘...")
    env = EnvironmentHandler.create_environment(
        config, 
        is_rendering_on=True, 
        is_evaluate_mode=True
    )
    
    # ë¹„ë””ì˜¤ ì €ì¥ ì¤€ë¹„
    try:
        import imageio
        video_enabled = True
        frames = []
        print("ğŸ“¹ ë¹„ë””ì˜¤ ë…¹í™” í™œì„±í™”ë¨")
    except ImportError:
        video_enabled = False
        print("âš ï¸ imageio ì—†ìŒ - ë¹„ë””ì˜¤ ì €ì¥ ê±´ë„ˆëœ€ (pip install imageio imageio-ffmpeg)")
    
    # Reference motion ë”°ë¼í•˜ê¸°
    print(f"\nğŸƒ Reference motion ì¬ìƒ ì‹œì‘ ({num_frames} í”„ë ˆì„)...")
    env.reset()
    
    # ì¹´ë©”ë¼ ì„¤ì • (ë‹¤ì–‘í•œ ê°ë„)
    camera_configs = {
        'front': {'distance': 3.0, 'azimuth': 90, 'elevation': -10, 'lookat': [0, 0, 1.0]},
        'side': {'distance': 3.0, 'azimuth': 0, 'elevation': -10, 'lookat': [0, 0, 1.0]},
        'diagonal': {'distance': 3.5, 'azimuth': 45, 'elevation': -20, 'lookat': [0, 0, 1.0]},
        'top': {'distance': 4.0, 'azimuth': 90, 'elevation': -60, 'lookat': [0, 0, 0.5]},
        'back': {'distance': 3.0, 'azimuth': 180, 'elevation': -10, 'lookat': [0, 0, 1.0]},
    }
    
    cam_config = camera_configs.get(camera_view, camera_configs['side'])
    env.viewer_setup(**cam_config)
    print(f"ğŸ“· ì¹´ë©”ë¼ ê°ë„: {camera_view} (azimuth={cam_config['azimuth']}Â°, elevation={cam_config['elevation']}Â°)")
    
    # Reference ë°ì´í„° í‚¤ ë§¤í•‘
    joint_names = config.env_params.reference_data_keys
    
    for frame_idx in range(min(num_frames, metadata['data_length'])):
        # Reference ìì„¸ë¡œ ì„¤ì •
        for joint_name in joint_names:
            q_key = f'q_{joint_name}'
            dq_key = f'dq_{joint_name}'
            
            if q_key in series_data and dq_key in series_data:
                try:
                    # Joint position ì„¤ì •
                    joint = env.sim.data.joint(joint_name)
                    joint.qpos[0] = series_data[q_key][frame_idx]
                    joint.qvel[0] = series_data[dq_key][frame_idx]
                except Exception as e:
                    if frame_idx == 0:
                        print(f"âš ï¸ Joint '{joint_name}' ì„¤ì • ì‹¤íŒ¨: {e}")
        
        # Forward kinematics ê³„ì‚°
        env.sim.forward()
        
        # í”„ë ˆì„ ìº¡ì²˜
        if video_enabled:
            try:
                # MuJoCo offscreen rendering
                frame = env.sim.renderer.render_offscreen(
                    width=640,
                    height=480,
                    camera_id=-1  # Free camera
                )
                frames.append(frame)
            except Exception as e:
                if frame_idx == 0:
                    print(f"âš ï¸ í”„ë ˆì„ ìº¡ì²˜ ì‹¤íŒ¨: {e}")
                    video_enabled = False
        
        # ì§„í–‰ë¥  í‘œì‹œ
        if frame_idx % 50 == 0:
            print(f"  Frame {frame_idx}/{num_frames} ({frame_idx/num_frames*100:.1f}%)")
        
        # ë Œë”ë§ ì†ë„ ì¡°ì ˆ
        import time
        time.sleep(1.0 / fps)  # ì‹¤ì‹œê°„ ì¬ìƒ
    
    env.close()
    
    # ë¹„ë””ì˜¤ ì €ì¥
    if video_enabled and len(frames) > 0:
        output_dir = Path(output_path).parent
        output_dir.mkdir(parents=True, exist_ok=True)
        
        video_path = Path(output_path)
        print(f"\nğŸ’¾ ë¹„ë””ì˜¤ ì €ì¥ ì¤‘... ({len(frames)} í”„ë ˆì„)")
        imageio.mimsave(str(video_path), frames, fps=fps)
        print(f"âœ… ë¹„ë””ì˜¤ ì €ì¥ ì™„ë£Œ: {video_path}")
        
        # í†µê³„ ì¶œë ¥
        print(f"\nğŸ“Š ë¹„ë””ì˜¤ ì •ë³´:")
        print(f"  - í”„ë ˆì„ ìˆ˜: {len(frames)}")
        print(f"  - FPS: {fps}")
        print(f"  - ê¸¸ì´: {len(frames)/fps:.2f} ì´ˆ")
        print(f"  - í•´ìƒë„: {frames[0].shape if frames else 'N/A'}")
    else:
        print(f"\nâš ï¸ ë¹„ë””ì˜¤ ì €ì¥ ì‹¤íŒ¨ (imageio í•„ìš”)")
    
    # ë°ì´í„° í†µê³„
    print(f"\nğŸ“ˆ Reference ë°ì´í„° í†µê³„:")
    for joint_name in joint_names[:5]:  # ì²˜ìŒ 5ê°œë§Œ í‘œì‹œ
        q_key = f'q_{joint_name}'
        if q_key in series_data:
            values = series_data[q_key]
            print(f"  {joint_name:20s}: min={values.min():7.3f}, max={values.max():7.3f}, mean={values.mean():7.3f}")

def main():
    parser = argparse.ArgumentParser(description='Reference motion ì‹œê°í™”')
    parser.add_argument('--config', type=str, 
                        default='rl_train/train/train_configs/S004_3D_IL_ver1_0_BASE.json',
                        help='í•™ìŠµ config JSON íŒŒì¼')
    parser.add_argument('--data', type=str, required=True,
                        help='Reference NPZ íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--output', type=str, default='reference_motion.mp4',
                        help='ì¶œë ¥ ë¹„ë””ì˜¤ íŒŒì¼')
    parser.add_argument('--frames', type=int, default=300,
                        help='ì¬ìƒí•  í”„ë ˆì„ ìˆ˜')
    parser.add_argument('--fps', type=int, default=30,
                        help='ë¹„ë””ì˜¤ FPS (ê¸°ë³¸: 30)')
    parser.add_argument('--camera', type=str, default='side',
                        choices=['front', 'side', 'diagonal', 'top', 'back'],
                        help='ì¹´ë©”ë¼ ê°ë„ (front: ì •ë©´, side: ì¸¡ë©´, diagonal: ëŒ€ê°ì„ , top: ìœ„, back: ë’¤)')
    
    args = parser.parse_args()
    
    visualize_reference_motion(
        args.config,
        args.data,
        args.output,
        args.frames,
        args.fps,
        args.camera
    )

if __name__ == '__main__':
    main()
